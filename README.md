# ğŸ§  Proyecto MLOps â€“ Pipeline de Entrenamiento, Inferencia, Monitoreo y Reentrenamiento

Este proyecto implementa un pipeline **MLOps completo** para un modelo de machine learning que predice el **target** a partir de datos transaccionales y de comportamiento de clientes.

Incluye:

âœ” Preprocesamiento automatizado  
âœ” Entrenamiento del modelo  
âœ” Monitoreo de *data drift*  
âœ” Reentrenamiento automÃ¡tico cuando drift > **0.15**  
âœ” Inferencia por lotes  
âœ” Postprocesamiento y valor de negocio  
âœ” Versionado con **DVC**  
âœ” Trazabilidad con **MLflow**  
âœ” ContenerizaciÃ³n con **Docker**

---

# ğŸ“ Estructura del proyecto
```
mlops_final/
â”œâ”€â”€ app/
â”‚ â””â”€â”€ app.py
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â”œâ”€â”€ training/ # p1_extrac.csv ... p4_extrac.csv
â”‚ â”‚ â””â”€â”€ inference/ # p5_extrac.csv
â”‚ â”œâ”€â”€ processed/
â”‚ â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â””â”€â”€ test/
â”‚ â”œâ”€â”€ postprocessed/
â”‚ â”œâ”€â”€ inference_logs/
â”‚ â”œâ”€â”€ drift/
â”‚ â””â”€â”€ monitoring_reports/
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ artifacts/ # model.pkl
â”‚ â””â”€â”€ pipelines/ # preprocess.pkl
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ preprocessing/
â”‚ â”‚ â””â”€â”€ prep_train.py
â”‚ â”œâ”€â”€ training/
â”‚ â”‚ â””â”€â”€ train.py
â”‚ â”œâ”€â”€ inference/
â”‚ â”‚ â””â”€â”€ infer_batch.py
â”‚ â”œâ”€â”€ postprocessing/
â”‚ â”‚ â””â”€â”€ postprocessing.py
â”‚ â”œâ”€â”€ monitoring/
â”‚ â”‚ â””â”€â”€ monitor.py
â”‚ â”œâ”€â”€ retraining/
â”‚ â”‚ â””â”€â”€ retrain.py
â”‚ â””â”€â”€ mlflow_tracking.py
â”œâ”€â”€ dvc.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

# ğŸ§¾ Dataset

El dataset contiene variables transaccionales, crediticias, comportamentales y operativas.  
El campo objetivo es:
target


### Archivos usados:

#### **Entrenamiento** (`data/raw/training/`)
- p1_extrac.csv  
- p2_extrac.csv  
- p3_extrac.csv  
- p4_extrac.csv  

#### **Inferencia** (`data/raw/inference/`)
- p5_extrac.csv  
*(si hay varios archivos, se toma el ultimo cargado)*

---

# ğŸ”„ Pipeline MLOps (definido en `dvc.yaml`)

El flujo completo estÃ¡ orquestado con **DVC**.

## 1ï¸âƒ£ Preprocesamiento â†’ `preprocess_train`
**Entrada:** archivos en `data/raw/training/`  
**Salida:**
- `train_arrays.npz`
- `test_arrays.npz`
- `preprocess.pkl`

Procesos:
- Limpieza
- Merge de particiones
- ImputaciÃ³n
- Encoding
- Split train/test

---

## 2ï¸âƒ£ Entrenamiento â†’ `train`
**Entrada:**
- `train_arrays.npz`
- `preprocess.pkl`

**Salida:**  
- `model.pkl`  
El modelo se registra con **MLflow**.

---

## 3ï¸âƒ£ Inferencia por lotes â†’ `infer_batch`
**Entrada:** primer archivo dentro de `data/raw/inference/`  
**Salida:**
- `log.csv`
- `predicciones_batch.csv`

---

## 4ï¸âƒ£ Postprocesamiento â†’ `postprocess`
Calcula valor de negocio por registro.

**Salida:**
- `business_value.csv`

---

## 5ï¸âƒ£ Monitoreo â†’ `monitor`
Genera reportes de drift comparando entrenamiento vs inferencia reciente.

**Salida:**
- `drift_report.html`
- `drift_report.json`
- `drift_flag.txt`  
(1 si drift > 0.15, 0 si no)

---

## 6ï¸âƒ£ Reentrenamiento automÃ¡tico â†’ `retrain`
Si `drift_flag.txt` indica drift, se reentrena el modelo.

---

# â–¶ï¸ EjecuciÃ³n del pipeline

### Ejecutar todo el pipeline
```bash```
dvc repro

### Ejecutar solo una etapa
dvc repro train

### Ejecutar reentrenamiento manualmente
python src/retraining/retrain.py

ğŸ“¦ Docker
### Construir la imagen
docker-compose build

### Ejecutar el contenedor
docker-compose up

### Iniciar app (Streamlit):
http://localhost:8501/

ğŸ“Š MLflow
### Iniciar interfaz de experimentos:
mlflow ui
http://localhost:5000/

ğŸ“š Requisitos
### Instalar dependencias:
pip install -r requirements.txt